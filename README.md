### CABLE
Continual learning seeks to learn from a stream of tasks and primarily focuses on mitigating catastrophic forgetting and enhancing knowledge transfer in dynamic environments. Recent advancements in dynamic architectures have introduced task-specific layers, such as adapters or experts, that enable continual learning while leveraging a fixed, pre-trained backbone. However, the challenge of inferring task information from incoming examples remains, leading to the development of task-agnostic methods and dynamic task detection techniques. Despite these innovations, existing approaches often overlook the potential for effectively learning new tasks using existing adapters, which can facilitate forward and backward transfer. This article addresses the critical issue of identifying tasks that can be learned without requiring additional adapters, thereby minimizing the need to initialize new parameters. We propose a novel methodology, Continual Adapter-Based Learning (CABLE), that utilizes reinforcement learning to evaluate the similarity of loss gradients between previously learned tasks and new examples. This similarity score informs a policy for dynamic adapter assignment, rewarding positive model performance and employing a gamified approach to task recognition. We demonstrate our method's effectiveness on classic image classification tasks and trajectory forecasting. Our findings indicate that this method mitigates catastrophic forgetting and promotes efficient knowledge transfer across tasks.
